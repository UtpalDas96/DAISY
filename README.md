# ðŸŒ¼ DAISY â€” Deloitte AI System

**Purpose**: DAISY is a repository template and starter kit to help Deloitte teams build an internal AI practice. It contains curated study material, boilerplate code for ML/Generative/Production workflows, tutorial links, onboarding checklists, and reusable GitHub templates.

---

## Quick goals

* Centralize learning resources (reading lists, courses, cheat-sheets).
* Provide production-ready boilerplate (Python packages, FastAPI inference, Docker, CI/CD).
* Include reproducible examples (notebooks, small datasets, experiments).
* Provide governance & contribution guidelines for internal teams.

---

## Top-level structure (suggested)

```
DAISY/
â”œâ”€ .github/
â”‚  â”œâ”€ workflows/
â”‚  â”‚  â”œâ”€ ci.yml
â”‚  â”‚  â””â”€ publish.yml
â”‚  â”œâ”€ ISSUE_TEMPLATE/
â”‚  â”‚  â”œâ”€ bug.md
â”‚  â”‚  â””â”€ feature_request.md
â”‚  â””â”€ PULL_REQUEST_TEMPLATE.md
â”œâ”€ docs/
â”‚  â”œâ”€ learning_path.md
â”‚  â”œâ”€ onboarding.md
â”‚  â””â”€ style_guides.md
â”œâ”€ study_material/
â”‚  â”œâ”€ readme.md
â”‚  â”œâ”€ courses.md
â”‚  â””â”€ cheat_sheets/
â”œâ”€ boilerplate/
â”‚  â”œâ”€ python_package_template/
â”‚  â”‚  â”œâ”€ src/aaa/
â”‚  â”‚  â”œâ”€ tests/
â”‚  â”‚  â”œâ”€ pyproject.toml
â”‚  â”‚  â””â”€ README.md
â”‚  â”œâ”€ fastapi_inference/
â”‚  â”‚  â”œâ”€ app/
â”‚  â”‚  â”œâ”€ Dockerfile
â”‚  â”‚  â””â”€ requirements.txt
â”‚  â””â”€ streaming_agent_template/
â”œâ”€ tutorials/
â”‚  â”œâ”€ 01-training-basics.ipynb
â”‚  â”œâ”€ 02-fine-tuning.ipynb
â”‚  â””â”€ 03-rag-with-neo4j.md
â”œâ”€ examples/
â”‚  â”œâ”€ small_classification/
â”‚  â””â”€ rag_demo/
â”œâ”€ infra/
â”‚  â”œâ”€ terraform/
â”‚  â””â”€ k8s/
â”œâ”€ scripts/
â”‚  â””â”€ helper_scripts.sh
â”œâ”€ LICENSE
â”œâ”€ README.md
â”œâ”€ CONTRIBUTING.md
â””â”€ CODE_OF_CONDUCT.md
```

---

## README.md (starter)

````
# DAISY â€” Deloitte AI System

DAISY is a starter repo to accelerate building AI capability across Deloitte teams. It contains curated study material, production-ready boilerplate, tutorials and examples.

## Contents
- `study_material/` â€” curated learning paths & cheat-sheets
- `boilerplate/` â€” reproducible templates (Python package, inference API, Docker)
- `tutorials/` â€” step-by-step tutorials & notebooks
- `examples/` â€” small runnable demos
- `docs/` â€” onboarding, style guides

## Get started (local)
1. Clone:
   ```bash
   git clone git@github.com:YOUR_ORG/DAISY.git
   cd DAISY
````

2. Create a Python venv and install dependencies (example for boilerplate FastAPI):

   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install -r boilerplate/fastapi_inference/requirements.txt
   uvicorn boilerplate.fastapi_inference.app.main:app --reload
   ```

## Contributing

See `CONTRIBUTING.md`.

## License

This project uses the MIT License â€” see `LICENSE`.

```
```

---

## Example CONTRIBUTING.md (high level)

* Use issues for feature requests & bugs.
* Follow the branching model: `main` (stable), `dev` (integration), feature branches as `feature/<short-desc>`.
* Add unit tests for new code (pytest).
* Run formatters and linters before PR (black, ruff, isort).
* Fill PR template and link related issues.

---

## Suggested CI: .github/workflows/ci.yml (summary)

* Matrix: python versions (3.10, 3.11)
* Steps: checkout, setup python, install deps, run ruff/black check, run pytest, build Docker image (optional)

(Include an actual example `ci.yml` when you want â€” I can paste a ready-to-run GitHub Actions file.)

---

## Boilerplate highlights

**Python package template**

* `pyproject.toml` + `poetry` or `pip`-native layout
* `src/` layout, proper unit tests, `tox` or `nox` matrix for testing

**FastAPI inference service**

* Health endpoint
* /predict endpoint: accepts JSON, returns predictions
* Model loading from `models/` or huggingface/onnx cache
* Dockerfile optimized for small image (multi-stage)

**RAG / Vector Store example**

* Notebook showing embedding generation (sentence-transformers), vector store (FAISS or Neo4j vector) and a minimal RAG pipeline

**Agent template**

* Shell to integrate a planner, executor, and tool wrappers (calendar, slack, google drive) â€” safe mocked integrations

---

## Study material (example lists)

* Foundations: Linear Algebra, Probability, Optimization â€” recommended books and 3-week study plan.
* ML: CS229 notes, Fast.ai course, Hands-On ML (AurÃ©lien GÃ©ron)
* LLMs: Papers: Attention Is All You Need, Transformer surveys; Tutorials: Hugging Face course; Practical: fine-tuning, inference optimization.
* Responsible AI: fairness, explainability, model cards (write templates in `docs/`)

---

## Governance & Templates

* `MODEL_CARDS/` template for every model added
* `SECURITY.md` quick guide for handling data and secrets
* `DATA_LICENSES.md` guidance on allowed datasets

---

## Onboarding checklist (docs/onboarding.md)

* Setup GitHub + 2FA
* Access to Deloitte internal packages/registry
* Follow `README` and run first demo
* Complete "DAISY learning path" (first three modules)

---

## Next steps I can do for you (pick any and I will execute now):

* Generate full `ci.yml` GitHub Actions file.
* Create a ready-to-copy `FastAPI` inference boilerplate (complete with Dockerfile and sample model loader).
* Produce `pyproject.toml` + package skeleton for `python_package_template`.
* Produce `README.md`, `CONTRIBUTING.md`, `LICENSE` full content files for you to paste into the repo.

---

If you want I can now generate specific files (CI, FastAPI sample, Python package skeleton) â€” say which one and I'll produce the full content ready to paste.

*â€” Utpal (DAISY helper)*
